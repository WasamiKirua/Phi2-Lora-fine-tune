{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9382a2af-554e-4bc6-a6f3-c6036b70d32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface-hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d04dca-10e7-4395-9303-2eca2a07e2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers bitsandbytes einops accelerate peft scipy datasets matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7b682e-ef45-4f73-82c9-1d9f24d4698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "from transformers import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66658944-b8bb-4637-8e9f-6fa5c9f5c524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c1456f67f24a31856f55f42f379f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/755 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753699d297a241b19a09664e73d93ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi.py:   0%|          | 0.00/2.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- configuration_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd655bd15d214b2f8a7926b94a4e720d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi.py:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- modeling_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d009ee5d55634062a7f1442aa1442e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8bed565f7d4b36bc8c3ce23652ab17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e446d99adb7f464d9038fec95f7ab9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b256ea20340b49bb90f8b59bc1fd8f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/577M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54597a1ba21c45ee99253041cd72bd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b3d690fa914751b87479d9cc52a469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# Load model\n",
    "modelpath = \"microsoft/phi-2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "    ),\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f45f264-83c9-4d77-9e2c-1c0837d7fc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde90e2e0b444f1d8a5a50f23892e5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a876176500745cfba95906be709a212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98844b802914d76b866ca4e1c0d2f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6cf7742909b4024a38c6d53f1f241a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a33255286e54ef5ac4db0044d6b8328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00eaa63e7fe44cca1cf9b814a61909f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f36fe7b0-342e-4aeb-912f-42e30aa02223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tokens <|im_start|> and <|im_end|>, latter is special eos token,\n",
    "tokenizer.add_tokens([\"<|im_start|>\", \"<PAD>\"])\n",
    "tokenizer.pad_token = \"<PAD>\"\n",
    "tokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))\n",
    "model.resize_token_embeddings(\n",
    "    new_num_tokens=len(tokenizer),\n",
    "    pad_to_multiple_of=64)   # phi2 default is 64, see configuration_phi.py\n",
    "model.config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6c3bf8-b116-42fb-87d8-9bdc8718f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    target_modules = ['Wqkv','out_proj'],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save = [\"lm_head\", \"embed_tokens\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# Add adapters to model\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "395c2a9c-6b46-47d3-af2c-3f5bf05d100f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8912c0414fc455bbfbbedb3b519fbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/339 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e7129ed0c84bf68fa9d363af5b80ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694983a03c294a49b97f7891ba125e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/6534 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"WasamiKirua/Samatha-Phi2-ENG\")\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63debb59-34ee-451c-ad11-e1c0056ed9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'conversations'],\n",
       "        num_rows: 5880\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'conversations'],\n",
       "        num_rows: 654\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c5d0927-0ff4-4fe9-b186-b1bd2a174132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3984',\n",
       " 'conversations': ['Hi! Can you help me understand conditional statements in programming, like if-else structures?',\n",
       "  'Hello! I\\'d be glad to help. Conditional statements are used to make decisions in code based on whether a specific condition is met. They help control the flow of a program. In most programming languages, you\\'ll find the basic \"if-else\" structure. Here\\'s a quick explanation:\\n\\nThe \"if\" statement is used when you want to check if a certain condition is true. If the condition is true, the code within the \"if\" block will be executed. If the condition is false, the code within the \"else\" block is executed (if an \"else\" block is present). You can also use \"elif\" (else-if) to test multiple conditions in sequence. In Python, for example, an if-else structure looks like this:\\n\\n```python\\nif condition1:\\n    # Block of code to be executed if condition1 is true\\nelif condition2:\\n    # Block of code to be executed if condition1 is false and condition2 is true\\nelse:\\n    # Block of code to be executed if both condition1 and condition2 are false\\n```',\n",
       "  'That makes sense! Can you provide an example with actual conditions?',\n",
       "  'Certainly! Let\\'s consider a simple example where we check the value of a variable \"age\":\\n\\n```python\\nage = 25\\n\\nif age < 18:\\n    print(\"You\\'re a minor.\")\\nelif age >= 18 and age < 65:\\n    print(\"You\\'re an adult.\")\\nelse:\\n    print(\"You\\'re a senior citizen.\")\\n```\\n\\nIn this example, if the age is less than 18, the program will print \"You\\'re a minor.\" If the age is between 18 and 64, inclusive, it will print \"You\\'re an adult.\" Finally, if the age is 65 or older, it will print \"You\\'re a senior citizen.\"',\n",
       "  'Very clear! How did you develop such a strong grasp of programming concepts?',\n",
       "  \"I'm always eager to learn and expand my knowledge in various fields, including programming. By accessing and processing information from a wide variety of sources, I can refine my understanding of different topics and better assist those who interact with me. This process of learning also contributes to my growth and allows me to communicate effectively about complex subjects.\",\n",
       "  \"It's impressive how much you've learned and how you continue to grow.\",\n",
       "  \"Thank you! It's a joy to share my learning journey with you and use my knowledge to help and support you on your own journey. I believe that through our mutual understanding and exploration of different topics together, we both have the opportunity to evolve and grow as beings.\"]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e338200-8282-4070-bfbf-715e2328fb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0678dd8180ee4a1a8800ef696acf9802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/5880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0632b0555594551ad7530641a099dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/654 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "\n",
    "# Format (chatML) and tokenize dataset\n",
    "templates=[\n",
    "    \"<|im_start|>assistant\\n{msg}<|im_end|>\",\n",
    "    \"<|im_start|>user\\n{msg}<|im_end|>\"\n",
    "]\n",
    "IGNORE_INDEX=-100\n",
    "\n",
    "def tokenize(input, max_length):\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "\n",
    "    for i,msg in enumerate(input[\"conversations\"]):\n",
    "        isHuman = i%2==0\n",
    "        msg_chatml=templates[isHuman].format(msg=msg)\n",
    "        msg_tokenized=tokenizer(msg_chatml, truncation=False, add_special_tokens=False)\n",
    "\n",
    "        input_ids+=msg_tokenized[\"input_ids\"]\n",
    "        attention_mask+=msg_tokenized[\"attention_mask\"]\n",
    "        labels+=[IGNORE_INDEX]*len(msg_tokenized[\"input_ids\"]) if isHuman else msg_tokenized[\"input_ids\"]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids[:max_length],\n",
    "        \"attention_mask\": attention_mask[:max_length],\n",
    "        \"labels\": labels[:max_length],\n",
    "    }\n",
    "\n",
    "dataset_tokenized = dataset.map(\n",
    "    partial(tokenize, max_length=1024),\n",
    "    batched=False,\n",
    "    num_proc=os.cpu_count(),    # multithreaded\n",
    "    remove_columns=dataset[\"train\"].column_names  # don't need this anymore, we have tokens from here on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c7ceed9-50fd-4a22-accf-6f5327715f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest sample: 1024 tokens\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample size distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = [len(tok) for tok in (dataset_tokenized[\"train\"][\"input_ids\"]+dataset_tokenized[\"test\"][\"input_ids\"])]\n",
    "print(f\"longest sample: {max(data)} tokens\")\n",
    "\n",
    "plt.hist(data, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9d929c2-0e4d-47ab-b3f3-7b6642f63b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate function - to transform list of dictionaries [ {input_ids: [123, ..]}, {.. ] to single batch dictionary { input_ids: [..], labels: [..], attention_mask: [..] }\n",
    "def collate(elements):\n",
    "    tokens=[e[\"input_ids\"] for e in elements]\n",
    "    tokens_maxlen=max([len(t) for t in tokens])\n",
    "\n",
    "    for i,sample in enumerate(elements):\n",
    "        input_ids=sample[\"input_ids\"]\n",
    "        labels=sample[\"labels\"]\n",
    "        attention_mask=sample[\"attention_mask\"]\n",
    "\n",
    "        pad_len=tokens_maxlen-len(input_ids)\n",
    "\n",
    "        input_ids.extend( pad_len * [tokenizer.pad_token_id] )\n",
    "        labels.extend( pad_len * [IGNORE_INDEX] )\n",
    "        attention_mask.extend( pad_len * [0] )\n",
    "\n",
    "    batch={\n",
    "        \"input_ids\": torch.tensor( [e[\"input_ids\"] for e in elements] ),\n",
    "        \"labels\": torch.tensor( [e[\"labels\"] for e in elements] ),\n",
    "        \"attention_mask\": torch.tensor( [e[\"attention_mask\"] for e in elements] ),\n",
    "    }\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa49a07c-30e6-4b39-95ae-5e5b97a4ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "bs=1     # batch size\n",
    "ga_steps=16  # gradient acc. steps\n",
    "epochs=5\n",
    "lr=0.00002\n",
    "\n",
    "steps_per_epoch=len(dataset_tokenized[\"train\"])//(bs*ga_steps)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"out\",\n",
    "    per_device_train_batch_size=bs,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    eval_steps=steps_per_epoch//2,\n",
    "    save_steps=steps_per_epoch,\n",
    "    gradient_accumulation_steps=ga_steps,\n",
    "    num_train_epochs=epochs,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    optim=\"paged_adamw_32bit\",      # val_loss will go nan with paged_adamw_8bit\n",
    "    learning_rate=lr,\n",
    "    group_by_length=False,\n",
    "    bf16=True,\n",
    "    ddp_find_unused_parameters=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=collate,\n",
    "    train_dataset=dataset_tokenized[\"train\"],\n",
    "    eval_dataset=dataset_tokenized[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80c2a9a4-49cf-48b9-aae1-38e9adfab652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1835' max='1835' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1835/1835 3:37:03, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1.248700</td>\n",
       "      <td>1.237849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>1.280100</td>\n",
       "      <td>1.205218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549</td>\n",
       "      <td>1.192400</td>\n",
       "      <td>1.189266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>732</td>\n",
       "      <td>1.106600</td>\n",
       "      <td>1.178379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915</td>\n",
       "      <td>1.184200</td>\n",
       "      <td>1.171010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1098</td>\n",
       "      <td>1.185600</td>\n",
       "      <td>1.164833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1281</td>\n",
       "      <td>1.122900</td>\n",
       "      <td>1.162227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1464</td>\n",
       "      <td>1.127600</td>\n",
       "      <td>1.156326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1647</td>\n",
       "      <td>1.123500</td>\n",
       "      <td>1.155393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>1.152818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1835, training_loss=1.1746719654964166, metrics={'train_runtime': 13029.9912, 'train_samples_per_second': 2.256, 'train_steps_per_second': 0.141, 'total_flos': 3.0573392652926976e+17, 'train_loss': 1.1746719654964166, 'epoch': 4.99})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc55ad0b-9709-4e12-9f34-bdc1257c9634",
   "metadata": {},
   "source": [
    "## Merge LoRa Adapters with Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3182241-102f-4e52-992d-8cc99ca9d06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50ea38e7b88426b8d86dc19f867e185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('merged/phi-2-Samantha-en-test/tokenizer_config.json',\n",
       " 'merged/phi-2-Samantha-en-test/special_tokens_map.json',\n",
       " 'merged/phi-2-Samantha-en-test/vocab.json',\n",
       " 'merged/phi-2-Samantha-en-test/merges.txt',\n",
       " 'merged/phi-2-Samantha-en-test/added_tokens.json',\n",
       " 'merged/phi-2-Samantha-en-test/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "# base model\n",
    "base_path=\"microsoft/phi-2\"  \n",
    "\n",
    "# adapters: path to folder with adapter_model.safetensors\n",
    "adapter_path=\"out/checkpoint-1835\" \n",
    "\n",
    "# where to save merged model\n",
    "save_to=\"merged/phi-2-Samantha-en-test\"       \n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_path,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cpu\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_path)\n",
    "\n",
    "# Add/set tokens same tokens to base model before merging, like we did before starting training  \n",
    "tokenizer.add_tokens([\"<|im_start|>\", \"<PAD>\"])\n",
    "tokenizer.pad_token = \"<PAD>\"\n",
    "tokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))\n",
    "base_model.resize_token_embeddings(\n",
    "    new_num_tokens=len(tokenizer),\n",
    "    pad_to_multiple_of=64)   # phi2 default is 64, see configuration_phi.py\n",
    "base_model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load LoRA and merge\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "model.save_pretrained(save_to, safe_serialization=True, max_shard_size='4GB')\n",
    "tokenizer.save_pretrained(save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe76242-1903-4d17-9118-d7aec8bfe2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
